{"archive":{"blogPosts":[{"id":"PikiwiDB-Pika--4.0.0","metadata":{"permalink":"/blog/PikiwiDB-Pika--4.0.0","source":"@site/blog/2024-07-08-PikiwiDB(Pika)-4.0.0.md","title":"What's new in PikiwiDB(Pika) v4.0.0","description":"尊敬的社区成员及技术爱好者们：","date":"2024-07-08T00:00:00.000Z","tags":[],"readingTime":17.605,"hasTruncateMarker":false,"authors":[{"name":"360 车金鸽","title":"Pika 开源社区"}],"frontMatter":{"title":"What's new in PikiwiDB(Pika) v4.0.0","slug":"PikiwiDB-Pika--4.0.0","authors":[{"name":"360 车金鸽","title":"Pika 开源社区"}],"hide_table_of_contents":false},"unlisted":false,"nextItem":{"title":"What's new in PikiwiDB(Pika) v3.5.4","permalink":"/blog/Pika-3.5.4"}},"content":"尊敬的社区成员及技术爱好者们：\n\nPikiwiDB 社区荣耀地宣告 —— 经过 9 个月打磨并在生产环境稳定运行 5 个月的 PikiwiDB (Pika) v4.0.0 【下文简称 Pika】今天正式发布。希望基于第三代存储引擎 Floyd 的这个新版本能为社区用户们带来更卓越的体验。\n\n# **1 重大改进**\n\n## **1.1 第三代存储引擎 Floyd**\n\nFloyd 如同其前代 Blackwidow，基于 RocksDB，不仅支持基础的 String 结构，也原生支持了 Hash、List、Set、Stream 及 ZSet 等 KKV 形式的复合数据结构。\n\n- **RocksDB 实例数可配置**\n\n摒弃了 Blackwidow 按数据类型采用 RocksDB 实例的物理隔离模式，Floyd 采用了 RocksDB 的 Column-Family 虚拟隔离机制，在单个 RocksDB 实例下可存储所有类型的数据。\n\n用户可自由设定 Pika 实例中每个 DB【等同于 Redis DB】中 RocksDB 实例的数量，而数据的存储则依据 key 的 hash 值分配至相应的 RocksDB 实例，减小了数据的空间放大和读放大效应，实现了机器资源的高效利用。\n\n- **强类型 key**\n\n![](https://private-user-images.githubusercontent.com/73943232/333059521-afa8a2bf-cebf-481f-a370-deaf4386b46b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA1MjU4NzYsIm5iZiI6MTcyMDUyNTU3NiwicGF0aCI6Ii83Mzk0MzIzMi8zMzMwNTk1MjEtYWZhOGEyYmYtY2ViZi00ODFmLWEzNzAtZGVhZjQzODZiNDZiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA5VDExNDYxNlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTlkMzcyYWU4NzI4ZDkyYjliZTg3NjM1YTI4ZjhlMzUwMDlmYWJmYzMzZTJkMzY4ZTYwMzk2NGJiNDhkNDc0ZWImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.FHMEJbqfdxgE3asbq8neuN4SMyDpyZHlpRSNy7JH1Zo)\n\n基于 RocksDB 的 Column-Family 虚拟隔离机制，Floyd 把所有类型的 key 和 string 一起存储在 Column-Family 0。\n\n在此存储基础之上，不同于 Blackwidow，可明确禁止不同类型的 key 重复【强类型】，这一设计旨在杜绝潜在的数据冗余与不一致性，与 Redis 服务特性保持一致，进一步提升了系统的整体效率与数据质量。\n\nPika v2.x 系列版本基于存储引擎 Nemo，v3.x 系列版本基于 Blackwidow，它们因为采用了物理隔离机制，无法低成本实现强类型 key，所有在 Redis TYPE 命令的结果中可能返回多种类型，而 Floyd 则完全兼容 Redis 只返回一种类型。\n\n- **Floyd 详细说明**\n\n如果对 Floyd 存储引擎感兴趣，请详阅《Floyd 存储引擎》\n\n【链接：https://github.com/OpenAtomFoundation/pika/discussions/2052】\n\n由于 Floyd 前后进行了多个版本的迭代，所以阅读该 github discussion 文档时请注意前后时间，如有相关冲突性说法，以最新日期的文字为准。\n\n关键 PR：\nPikiwiDB(Pika) 支持 Floyd 存储引擎\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2413\n\n添加 Floyd 的 compaction-filter 的 Gtest\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2669\n\nPika 不支持不同类型的重复 key, 写入重复 key 返回非法类型\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2609\n\n对 HyperLogLog 和 String 进行类型隔离，确保 HyperLogLog 操作与 String 操作明确区分开\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2720\n\n添加支持分区索引过滤的功能\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2601\n\n## **1.2 Mget 批量查询缓存**\n\nPika v3.5.2 的热数据缓存只实现了对热点 Key 的点查 (如 get/hget)，在后续的 v3.5.3 和 v3.5.4 修复若干 bug 后，对热数据的点查目前已经非常稳定。然而并未支持批量查询 (如 mget etc)。\n\n内部业务侧反馈批量查询速度比较慢，在 40C/256GiB/2TiB SATA SSD 规格机器上数据量超过 100GiB 时，Pika v3.3.6 30% 批量查询延迟超过 35ms。但由于 Pika 热数据缓存尚未支持批量查询，性能并未改善。\n\n为了满足业务需求，Pika 团队开发了批量查询热数据缓存功能，显著提升了批量查询性能，降低了查询延迟和失败率。相关技术细节请阅读《PikiwiDB (Pika) 混合存储之批量查询》 \n\n【链接：https://mp.weixin.qq.com/s/KFLPruSdB66TMRxUfR9PbQ 】。\n\n\n\n关键 PR ：\n\nMget 支持多 key 查询缓存，记录未命中的 key 去 DB 中查询，提升 Pika 服务的读性能\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2675\n\n修复 Mget 没有使用解析 ttl 的函数导致出现部分 key 的 ttl 未被更新，数据不一致的问题\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2730\n\n\n## **1.3 主从复制**\n\nPika v3.3.6 有很多主从复制的缺陷。v4.0.0 版本对 Pika 全量复制及增量复制进行了大量优化和 bug 修复，取得了非常好的效果。 \n\n并在 info 命令中输出了 \"repl_connect_status\" 指标 (PR 2638)，以方便用户更加明确清晰的确定当前的主从复制状态。\n\n关键 PR ：\n\n修复批量扩容时，多个 slave 同时连接 master, 短时间多次 bgsave 导致部分从节点数据不完整的问题\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2746\n\n修复 Spop 在写 binlog 时可能会出现竞态问题\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2647\n\n修复多 DB 下全量同步超时后不重试的问题\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2667\n\n修复多 DB 主从超时场景下，可能会出现窗口崩溃的问题\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2666\n\n修复主从同步限速逻辑中重复解锁的问题\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2657\n\n重构主从复制模式 slave 节点的主从同步线程模型，尽可能减少 binlog 消费阻塞问题\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2638\n\n## **1.4 Redis Stream**\n\nRedis Stream 类似于消息队列（MQ），以便更安全地传递消息。\n\n为了确保数据的安全性，底层引擎 BlackWidow 和 Floyd 中特别添加了对 Stream 数据类型的支持。\n\n关键 PR： \n\n修复 pkpatternmatchdel 命令使用错误导致的 stream 类型数据删除异常的问题\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2726\n\n修复 Keyspace 命令未计算 Stream 类型数据的问题\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2705\n\n## **1.5 Compaction**\n\nPikiwiDB (Pika) 的底层磁盘存储引擎 RocksDB 在进行 compaction 时会显著影响 PikiwiDB (Pika) 的读写性能。\n\n因此，控制好 compaction 是优化 Pika 读写性能的关键。\n\nFloyd 使用了 v8.7.3 版本的 RocksDB，开放了更多 RocksDB 参数，以方便用户优化 RocksDB 性能：\n\n1. enable-partitioned-index-filters： 支持加载分区索引过滤器，加快 RocksDB 查找速度。\n2. min-write-buffer-number-to-merge: 默认值为 1，如果将此值设置得更大，意味着需要更多的写缓冲区被填满后才进行 flush。这样可以减少 flush 的频率，增加数据在内存中的累积量，从而可能提高写入吞吐量。\n3. level0-stop-writes-trigger: 默认值为 36，定义了 L0 层中 sst 文件的最大数量，一旦达到这个数量，RocksDB 将会采取 **暂停写入、强制 compaction** 等措施来防止写入操作继续累积，以避免 L0 层变得过于庞大，进而可能导致写入放大、查询性能下降等问题。\n4. level0-slowdown-writes-trigger：默认值为 20，用于控制当 Level 0 的 SST 文件数量达到这个阈值时，触发写减速（write slowdown），防止 Level 0 的文件数量过多，导致后续 compaction 操作的压力过大。\n5. level0-file-num-compaction-trigger：默认值为 4，当 Level 0 的 SST 文件数量达到这个参数设定的阈值时，RocksDB 会开始执行 compaction 操作，将 Level 0 的文件合并到 Level 1，以减少 Level 0 的文件数量，降低读取延迟，并优化存储空间的利用率。\n6. max-subcompactions：默认值为 1，用于控制 RocksDB 中并发执行的 sub-compaction 任务数量，其值为 1 表示关闭 sub-compaction。如果系统资源充足，建议提升该参数以优化 compaction 效率。\n7. max-bytes-for-level-base：指定了 L1 SST 文件总的大小。这个大小是 RocksDB 进行数据分层管理和 compaction 决策的重要依据：如果 L1 层的大小设置得太小，可能会导致 L0 层的 compaction 过于频繁，进而影响写性能。反之，如果设置得太大，可能会占用较多的磁盘空间，并且影响读取性能，因为读取操作可能需要跨越更多的层级。Pika 没有在 pika.conf 中开放此参数给用户配置，而是使用其他参数（**level0-file-num-compaction-trigger** 和 **write-buffer-size**）计算后的结果。\n\n```\nstorage_options_.options.max_bytes_for_level_base = g_pika_conf->level0_file_num_compaction_trigger() * g_pika_conf->write_buffer_size()\n```\n\n关键 PR：\n添加 Floyd 的 compaction-filter 的 Gtest\nhttps://github.com/OpenAtomFoundation/pika/pull/2669\n添加支持分区索引过滤的功能\nhttps://github.com/OpenAtomFoundation/pika/pull/2601\n新增 RocksDB Compaction 策略动态调整参数，用户可以根据业务调整 Compaction 策略，降低 Compaction 操作对服务性能的损耗\nhttps://github.com/OpenAtomFoundation/pika/pull/2538\n\n## **1.6 可观测性**\n\nv3.5 版本增加了包括命中率、每秒命中次数、Redis Cache 内存使用量、Redis Cache 个数、Redis Cache DB 个数 等指标，但是在集群方面的可观测性是缺失的。v4.0.0 对 Codis-Proxy 的 P99、P999、延迟等监控指标进行采集和展示，可以直观地反映线上 Codis-proxy 的运行情况。\n\nv4.0.0 开始还提供新的工具：根据 pika benchmark 工具压测结果自动生成可视化的统计图表。\n\n关键 PR：\n\nCodis 支持 info 命令，可以通过该命令查询 Codis-proxy 的 info 信息\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2688\n\nCodis-proxy 新增 P99 P95 等监控耗时指标\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2668\n\n添加 Pika 压测指标，提升 Pika 压测效率，并输出可视化的统计图表\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2663\n\n## **1.7 测试集**\n\nPikiwiDB(Pika) 测试集由 gtest 单测、Redis TCL 测试集和 Go 测试集组成。v4.0.0 中丰富了诸多特性的 go test 功能，并进一步完善了基本数据类型的 TCL 测试。\n\n关键 PR：\n\n添加 Floyd 的 compaction-filter 的 Gtest\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2669\n\nPika Geo 数据类型增加 TCL 测试，并修复测试过程中遇到的缺陷\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2753\n\n## **1.8 跨平台** \n\nPikiwiDB(Pika) 以往仅支持 centos 和 ubuntu 等 linux 平台，v3.5 开始支持 Mac 等平台。v4.0.0 将对 Mac 平台的支持扩展至 FreeBSD 平台。\n\n关键 PR：\n\nPika 支持在 FreeBSD14 平台上进行编译\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2711\n\n# **2 改进列表**\n\n下面详细列出了本次发版的主要功能升级和改进。\n\n## **2.1 新特性**\n\n- Pika Geo 数据类型增加 TCL 测试，并修复测试过程中遇到的缺陷   \n  https://github.com/OpenAtomFoundation/pika/pull/2753\n\n- Pika 支持在 FreeBSD14 平台上进行编译打包   \n  https://github.com/OpenAtomFoundation/pika/pull/2711\n\n- Pika 线程整理，避免启动过多无用线程，对不同的线程进行命名，方便问题定位   \n  https://github.com/OpenAtomFoundation/pika/pull/2697\n\n- Mget 支持多 key 查询缓存，记录未命中的 key 去 DB 中查询，提升 Pika 服务的读性能   \n  https://github.com/OpenAtomFoundation/pika/pull/2675\n\n- Codis 支持 info 命令，可以通过该命令查询 Codis-proxy 的 info 信息   \n  https://github.com/OpenAtomFoundation/pika/pull/2688\n\n- 添加 Floyd 的 compaction-filter 的 Gtest   \n  https://github.com/OpenAtomFoundation/pika/pull/2669\n\n- Codis-proxy 新增 P99 P95 等监控耗时指标   \n  https://github.com/OpenAtomFoundation/pika/pull/2668\n\n- 添加 Pika 压测指标，提升 Pika 压测效率，并输出可视化的统计图表   \n  https://github.com/OpenAtomFoundation/pika/pull/2663\n\n- Pika 主从复制新增监控指标    repl_connect_status, 可以更加明确清晰的确定当前的主从复制的状态   \n  https://github.com/OpenAtomFoundation/pika/pull/2638\n\n- Pika 不支持不同类型的重复 key, 写入重复 key 返回非法类型   \n  https://github.com/OpenAtomFoundation/pika/pull/2609\n\n- 添加支持分区索引过滤的功能   \n  https://github.com/OpenAtomFoundation/pika/pull/2601\n\n- Pika 支持第三代存储引擎 Floyd, 通过支持多 rocksdb 实例、对 Blob 的使用进行优化、对过期数据的清理进行优化，提升了 Pika 实例的读写性能   \n  https://github.com/OpenAtomFoundation/pika/pull/2413\n\n\n## **2.2 bug 修复**\n\n- 修复 iter 未被析构，导致 pkpatternmatchdel 在返回之前不会删除 iter，这可能会导致 rocksdb 永远引用一个版本，导致数据不符合预期的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2785\n\n- 修复 config 参数 min-blob-size 带单位时解析错误的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2767\n\n- 修复 zverank 返回值异常的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2673\n\n- 修复 Pika-port 传输数据过程中报错的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2758\n\n- 修复因为堆上分配的缓冲区越界导致 Dbsize 命令运行时崩溃的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2749\n\n- 修复批量扩容时，多个 slave 同时连接 master, 短时间多次 bgsave 导致部分从节点数据不完整的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2746\n\n- 修复参数未初始化导致 slotsscan 等命令不能和 bgsave 命令相互制衡的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2745\n\n- 修复 Slotmigrate 迁移数据的过程中，返回值设置错误，异常场景下会终止数据迁移的问题    \n  https://github.com/OpenAtomFoundation/pika/pull/2741\n\n- 修复 Mget 没有使用解析 ttl 的函数导致出现部分 key 的 ttl 未被更新，数据不一致的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2730\n\n- 修复 pkpatternmatchdel 命令使用错误导致的 stream 类型数据删除异常的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2726\n\n- 修复 pkpatternmatchdel 不能正确删除掉对应的 keys 的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2717\n\n- 修复 ACL 密码验证错误问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2714\n\n- 修复 Keyspace 命令未计算 Stream 类型数据的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2705\n\n- 对部分命令定制化处理逻辑，避免写 binlog 导致从节点的 binlog 解析失败的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2793\n\n- 修复 Pika cmdID 赋值在 Cmd 初始函数中，可能会导致并发构造的时候出现内存泄漏的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2692\n\n- 修复 ExpectedStale 未考虑 String 类型，如果存在已经过期的 String 类型的 key, ExpectedStale 会返回错误的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2682\n\n- 修复 Spop 在写 binlog 时可能会出现竞态问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2674\n\n- db instance 设置不合理时，给用户错误提示   \n  https://github.com/OpenAtomFoundation/pika/pull/2672\n\n- 修复 server_stat 中的数据竞态问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2671\n\n- 修复多 DB 下全量同步超时后不重试的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2667\n\n- 修复多 DB 下全量同步超时后不重试的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2666\n\n- 修复主从同步限速逻辑中重复解锁的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2657\n\n- 发版支持自动打包 centos7 和 centos8 平台的二进制编译包   \n  https://github.com/OpenAtomFoundation/pika/pull/2535\n\n- 修复 Codis 侧的 getrange 命令没有返回预期结果的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2510\n\n## **2.3 提升改进项**\n\n- 更新 Pika Docker Readme, 可以按照 Readme 在 Docker 中部署 Pika 服务   \n  https://github.com/OpenAtomFoundation/pika/pull/2743\n\n- 优化重复查询 meta value 导致影响 Pika 服务读写性能的问题   \n  https://github.com/OpenAtomFoundation/pika/pull/2735\n\n- 支持对更多的 RocksDB 参数进行动态调整，用户根据不同的业务使用场景调整参数提升 Pika 的读写性能   \n  https://github.com/OpenAtomFoundation/pika/pull/2728\n\n- 对 HyperLogLog 和 String 进行类型隔离，确保 HyperLogLog 操作与 String 操作明确区分开   \n  https://github.com/OpenAtomFoundation/pika/pull/2720\n\n- 更新了 PR 标题验证，不允许在标题末尾出现中文字符   \n  https://github.com/OpenAtomFoundation/pika/pull/2718\n\n- 重构主从复制模式 slave 节点的主从同步线程模型，尽可能减少 binlog 消费阻塞问题    \n  https://github.com/OpenAtomFoundation/pika/pull/2638\n\n- 新增 RocksDB Compaction 策略动态调整参数，用户可以根据业务调整 Compaction 策略，降低 Compaction 操作对服务性能的损耗   \n  https://github.com/OpenAtomFoundation/pika/pull/2538\n\n## 2.4 发版 tag\n\n​    https://github.com/OpenAtomFoundation/pika/releases/tag/v4.0.0\n\n# **3 社区**\n\n感谢所有为 v4.0.0 做出贡献的社区成员，包括 issue/PR 提交者、代码 reviewer 【排名不分先后，依据字母序列】：\n\n- AlexStocks\n- baerwang\n- chejinge\n- cheniujh\n- chienguo\n- guangkun123\n- gukj-spel\n- longfar-ncy\n- lqxhub\n- luky116\n- Mixficsol\n- saz97\n- wangshao1\n\nPikiwiDB (Pika) 开源社区热烈欢迎您的参与和支持。如果您有任何问题、意见或建议，请扫码添加 PikiwiDB 小助手【微信号: PikiwiDB】为好友，它会拉您加入官方微信群。"},{"id":"Pika-3.5.4","metadata":{"permalink":"/blog/Pika-3.5.4","source":"@site/blog/2024-05-16-Pika-3.5.4.md","title":"What's new in PikiwiDB(Pika) v3.5.4","description":"PikiwiDB (Pika) 社区非常荣幸地宣布，我们的最新 v3.5.4 正式生产可用版本现已发布。","date":"2024-05-16T00:00:00.000Z","tags":[],"readingTime":6.53,"hasTruncateMarker":false,"authors":[{"name":"陈俊华","title":"360"}],"frontMatter":{"title":"What's new in PikiwiDB(Pika) v3.5.4","slug":"Pika-3.5.4","authors":[{"name":"陈俊华","title":"360"}],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"What's new in PikiwiDB(Pika) v4.0.0","permalink":"/blog/PikiwiDB-Pika--4.0.0"},"nextItem":{"title":"What's new in Pika v3.5.3 （英文版本）","permalink":"/blog/Pika-3.5.3-en"}},"content":"PikiwiDB (Pika) 社区非常荣幸地宣布，我们的最新 v3.5.4 正式生产可用版本现已发布。\n\nv3.5.4 解决了历史遗留的 bug，对 PikiwiDB (Pika) 的一些遗留 bug 进行修复和优化，旨在打造出一个高稳定性的版本。本次的重点优化主要包括，PikiwiDB (Pika) 支持动态调整限速参数、增强 PikiwiDB (Pika) 的客观测性指标、 磁盘 IO 限速支持读限速及写限速等。\n\n## 1 新特性\n\n1. Pika 支持动态调整全量同步限速参数 rsync-timeout-ms 和 throttle-bytes-per-second。\n\n自 v3.5.0 版本开始，PikiwiDB (Pika) 服务摒弃了通过子进程内使用原来 rsync 工具进行主从全量同步的逻辑，在 PikiwiDB (Pika) 内部以线程方式【称作 rsync 线程】自行实现了新的全量同步逻辑，避免因为外部进程不可控引起的主从同步问题，根据 360 内部 Pika 线上大规模集群运维的经验，在 PikiwiDB (Pika) 主从进行全量同步的过程中，如果遇到某些不利的外部因素，如网络波动，硬件故障（如网卡降速导致的主从网卡速率不匹配）等，可能引起 rsync 线程请求持续超时（PikiwiDB (Pika) 内置 rsync 模块用于全量同步阶段的文件传输），且超时重试所发出的包可能引发更大的网络信道负担。此时对于运维人员来说，如果能动态调整 rsync 请求的超时时间和 rsync 传输的速率上限，不仅意味着对全量同步阶段控制粒度的进一步细化，更大大降低了在该场景下的运维处置难度。\n\n关键 PR：\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2633\n\n2. 将 info key space 1 的结果输出至 info all 并展示到监控界面中。\n\nPikiwiDB (Pika) 是通过 Info 命令采集数据至 Pika-Exporter，展示到 Grafana 界面上的，目前界面上部分数据是没有展示的，如 keys 的数量，本次将执行 info keyspace 的结果展示到监控界面，用户可以通过这个指标来查看存储的量级等。\n\n关键 PR：\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2603\n\n3.Pika 磁盘 IO 限速参数支持 OnlyRead、OnlyWrite、ReadAndWrite，默认支持 OnlyWrite。\n\n自 3.5.0 版本开始，PikiwiDB(Pika) 服务可以通过调整 rate-limit 参数实现写限速，防止在网卡质量不高的情况下磁盘 IO 过重导致服务不可用，或者 binlog 阻塞的情况发生。360 内部 Pika 线上大规模集群运维的经验，在 PikiwiDB (Pika) 实例的网卡较差情况下，也需要对读实例进行限速，本次修改支持读、写限速，默认是写限速，调整 config 配置中的 rate-limiter-mode 可以设置为读限速，或者同时读写限速。\n\n关键 PR：\n\n- https://github.com/OpenAtomFoundation/pika/pull/2599\n\n2 改进列表\n\n- slotmigrate 添加 go test。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2576\n\n- INFO 命令耗时优化，降低查磁盘频率，避免因为数据采集调用 info 命令时查磁盘太过频繁导致服务性能下降。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2554\n\n- 对五种基本数据类型命令增加 Redis tcl 测试。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2527\n\n3 Bug 修复\n\n- 修复使用 Pika Exporter 时可能会出现 slots 分配不均衡的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2651\n\n- 修复 Codis dashboard 不能正确更新 master 实例状态的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2650\n\n- 修复 Redis 事务 binlog 解析失败导致的主从同步异常问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2642\n\n- 修复 Pika Expoter 启动时不带参数导致启动失败问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2640\n\n- 修复使用 Pika Operater 拉起集群 Codis-proxy panic 的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2633\n\n- 修复 CI 编译出的二进制进行自动化测试时 cp 命令失败问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2614\n\n- 修复变量未初始化导致 cache 启动失败的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2613\n\n- 修复 userpass 和 userblacklist 动态修改参数功能异常问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2600\n\n- 修复 scard sscan 结果不一致的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2596\n\n- 修复当 max-rsync-parallel-num 大于 4，slave 会在主从复制时 coredump 的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2595\n\n- 调整不常用的线程池线程数，避免因为空跑导致性能损耗。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2590\n\n- 修复 Pika 事务边缘测试 case 不通过的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2586\n\n- 将 cache-model 修改成 cache-mode。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2585\n\n- 修复使用 info keyspace 后，info all 死锁的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2584\n\n- 修复因修改 zsetscorekey comparator impl 字典序比较熟顺序，导致 353 352 极端场景不兼容的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2583\n\n- 修复 compact 死锁的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2581\n\n- Slotmigrate 添加 go test。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2576\n\n- 更新 Pika Operater 使用的 pika 版本。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2572\n\n- 修复 config rewrite 后 blockcache 数值异常的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2561\n\n- 修复 slotmigrate 动态修复后值错误的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2548\n\n- 修复 spop 可能会出现主从数据不一致的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2541\n\n- 修复 CloseFd (it->second [i]) 出现越界的问题。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2539\n\n- 修复 Flushall 和 FlushDB 死锁的隐患，并删除 FlushSubDB 接口。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2533\n\n- 增加参数控制是否清理 tcl 测试后产生的数据文件，防止废弃数据占据磁盘。\n\n  https://github.com/OpenAtomFoundation/pika/pull/2507\n\n4 社区\n\nPikiwiDB (Pika) 开源社区热烈欢迎您的参与和支持。如果您有任何问题、意见或建议，可通过以下渠道联系我们：\n\n![图片](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)\n\n\n![img](https://mp.weixin.qq.com/mp/qrcode?scene=10000004&size=102&__biz=Mzg4MTY2ODA1MQ==&mid=2247483978&idx=1&sn=b56b42fb857f2ef6cc4c57b18f205e92&send_time=)\n\n微信扫一扫\n关注该公众号"},{"id":"Pika-3.5.3-en","metadata":{"permalink":"/blog/Pika-3.5.3-en","source":"@site/blog/2024-03-27-Pika-3.5.3-en.md","title":"What's new in Pika v3.5.3 （英文版本）","description":"As Redis announces the adoption of dual protocols to maintain its commercial interests, the PikiwiDB (Pika) community is pleased to announce the release of the v3.5.3 stable version for production use today.","date":"2024-03-27T00:00:00.000Z","tags":[],"readingTime":8.965,"hasTruncateMarker":false,"authors":[{"name":"360 中间件团队","title":"Pika 开源社区"}],"frontMatter":{"title":"What's new in Pika v3.5.3 （英文版本）","slug":"Pika-3.5.3-en","authors":[{"name":"360 中间件团队","title":"Pika 开源社区"}],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"What's new in PikiwiDB(Pika) v3.5.4","permalink":"/blog/Pika-3.5.4"},"nextItem":{"title":"What's new in Pika v3.5.3 ","permalink":"/blog/Pika-3.5.3"}},"content":"As Redis announces the adoption of dual protocols to maintain its commercial interests, the PikiwiDB (Pika) community is pleased to announce the release of the v3.5.3 stable version for production use today.\n\nThe v3.5.3 version addresses historical bugs and introduces a multitude of new features. These features primarily include Pika's support for ACL, the removal of residual Slot code from the Sharing mode, separation of fast and slow commands, Redis Stream support, large key analysis tools, and Pika's distributed cluster support for fully automated failover, among others. Additionally, we have enriched the automation test cases in version 3.5.3 to enhance the stability and robustness of the Pika service, providing users with a more efficient and stable experience. This article will mainly elaborate on the significant features, bug fixes, and performance improvements in this update.\n\nBefore diving into the main release content of version 3.5.3, please note the following statements:\n\n1. Due to trademark issues, the Pika project has been renamed to PikiwiDB. In this article, we will use PikiwiDB (Pika) to refer to the project at https://github.com/OpenAtomFoundation/pika.\n2. We have created a new project https://github.com/OpenAtomFoundation/pikiwidb, which is a large-capacity KV database compatible with the Redis protocol and based on the Raft protocol. It is mainly designed for scenarios requiring strong consistency, such as storing metadata at a scale of about 10TiB. PikiwiDB will be used to refer to this project specifically.\n\n## 1 Major Improvements\n\n### 1.1 PikiwiDB (Pika) Supports ACL\n\nPikiwiDB (Pika) 3.5.3 now fully supports Redis ACL, laying a solid foundation for future multi-tenant support in cloud-native Pika clusters. Before 3.5.3, Pika already supported Redis user authentication methods such as auth/userpass/requirepass, as well as its own command blacklist mode configured through userblacklist in pika.conf. This update maintains backward compatibility and supports these existing methods.\n\nMoreover, we have integrated all Redis ACL TCL test suites into PikiwiDB (Pika)'s test suite to ensure that PikiwiDB (Pika)'s ACL implementation is fully compatible with Redis ACL.\n\nKey PRs:\n\n- [PikiwiDB (Pika) Supports ACL](https://github.com/OpenAtomFoundation/pika/pull/2013)\n- [Fixes ACL User Authentication Issues](https://github.com/OpenAtomFoundation/pika/pull/2449)\n- [ACL Backward Compatibility with Userblacklist](https://github.com/OpenAtomFoundation/pika/pull/2459)\n- [Adds Redis ACL Test Suites](https://github.com/OpenAtomFoundation/pika/pull/2495)\n\n### 1.2 Hybrid Storage Model Supports Bitmap\n\nIn a single-node environment, it is impossible to simultaneously optimize PikiwiDB (Pika)'s read/write/compaction, which is known as the \"impossible triangle.\" In version v3.5.2, we supported hybrid storage consisting of cached Redis and RocksDB, which supported five data structures: string/list/set/zset/hashtable. In this release, we have added support for bitmap: https://github.com/OpenAtomFoundation/pika/pull/2253\n\nAdditionally, we now support dynamic tuning of Redis cache parameters in version 3.5.3: https://github.com/OpenAtomFoundation/pika/pull/2197\n\n### 1.3 Separation of Fast and Slow Commands\n\nTo prevent slow commands from blocking the execution of fast commands, we have implemented the separation of fast and slow commands at both the Codis-Proxy and PikiwiDB (Pika) levels.\n\nhttps://github.com/OpenAtomFoundation/pika/pull/2162\n\n### 1.4 Redis Stream\n\nWhile PikiwiDB (Pika) previously supported Redis pubsub, which only allowed for online message passing, in version 3.5.3, we have added limited support for Redis Stream, similar to a message queue (MQ), to facilitate safer message transmission. To ensure data safety, we have specifically added support for the Stream data type in our underlying engine, BlackWidow.\n\nKey PR:\n\n- [Pika Supports Redis Stream](https://github.com/OpenAtomFoundation/pika/pull/1955)\n\nPlease note that Pika Stream currently does not support consumer group consumption and will be available in future updates.\n\n### 1.5 Cloud-Native Cluster\n\nIn PikiwiDB (Pika) 3.5.0, we open-sourced a Pika-Operator that supports deploying a pair of Pika master and slave on K8s. In version 3.5.2, based on Kubeblocks, our Pika-Operator supported deploying a Pika Cluster in the form of Codis on K8s, but it did not support dynamic scaling at the time.\n\nIn version 3.5.3, the latest Pika-Operator now supports node scaling at the Codis Group level and data rebalance.\n\nKey PRs:\n\n- [PikiwiDB (Pika) Operator Supports Pika Cluster Auto-Scaling](https://github.com/OpenAtomFoundation/pika/pull/2121)\n- [Optimizes Codis Slot Migration Speed, Supports Dynamic Adjustment of Migration Threads and Speed](https://github.com/OpenAtomFoundation/pika/pull/2486)\n- [Pika-Operator Supports Namespaces, Allows Deploying Different Clusters in Different Namespaces](https://github.com/OpenAtomFoundation/pika/pull/2480)\n- [Pika-Operator Supports Monitoring Metric Collection, Automatically Launches Pika-Exporter](https://github.com/OpenAtomFoundation/pika/pull/2451)\n\n### 1.6 Compaction Improvements\n\nPikiwiDB (Pika)'s underlying disk storage engine, RocksDB, significantly impacts PikiwiDB (Pika)'s read and write performance during compaction, which appears as \"spikes\" in monitoring systems. Controlling compaction is key to optimizing Pika's read and write performance.\n\nKey PRs for compaction improvements:\n\n- [Adds CompactRange Command to Support Compaction of a Specific Range of Keys](https://github.com/OpenAtomFoundation/pika/pull/2163)\n- [Improves Compaction Speed and Reduces Compaction Time](https://github.com/OpenAtomFoundation/pika/pull/2172)\n- [Invokes Disable Compaction When Executing Shutdown Command, Enhances Exit Speed](https://github.com/OpenAtomFoundation/pika/pull/2345)\n\n### 1.7 Automatic Failover\n\nPikiwiDB (Pika) clusters are currently based on Codis. To enhance the usability of PikiwiDB (Pika) Clusters based on Codis, we have made many extensions to Codis.\n\nThe original Codis did not support failover within Groups, requiring the use of Redis Sentinel, which increases operational costs. We have implemented auto failover for Groups within Codis Dashboard by drawing on the functionality of sentinel.\n\nKey PR:\n\n- [PikiwiDB (Pika) Distributed Cluster Supports Automatic Failover](https://github.com/OpenAtomFoundation/pika/pull/2386)\n\n### 1.8 Observability Enhancements\n\nThe key component for PikiwiDB (Pika) observability is Pika-Exporter. Although Redis Cache was added to the 3.5.2 version, it lacked monitoring metrics. In version 3.5.3, we have added metrics such as hit rate, hits per second, Redis Cache memory usage, number of Redis Caches, and number of Redis Cache DBs.\n\nKey PRs:\n\n- [Pika Exporter Exposes Cache-Related Data Collection Metrics](https://github.com/OpenAtomFoundation/pika/pull/2318)\n- [PikiwiDB (Pika) Distributed Cluster Codis Proxy Adds Observable Metrics](https://github.com/OpenAtomFoundation/pika/pull/2199)\n- [Fixes dbsize Calculation Error](https://github.com/OpenAtomFoundation/pika/pull/2494)\n- [Fixes Inaccurate Network Monitoring Metric Statistics](https://github.com/OpenAtomFoundation/pika/pull/2234)\n\n### 1.9 Data Consistency\n\nVersion 3.5.3 fixes numerous PikiwiDB (Pika) master-slave synchronization issues, ensuring data consistency.\n\nKey PRs:\n\n- [Fixes the Logic for Slave Nodes Receiving Exceptional Reply Packets from Masters During Full-Quantity Replication](https://github.com/OpenAtomFoundation/pika/pull/2319)\n- [Fixes Inconsistency Issues Between Cache and DB Data in Certain Scenarios](https://github.com/OpenAtomFoundation/pika/pull/2225)\n- [Fixes Data Loss Issues After Full-Quantity Replication Failure](https://github.com/OpenAtomFoundation/pika/pull/2439)\n- [Adds Data Synchronization Status During Full-Quantity Replication, Clarifying Data Synchronization Progress](https://github.com/OpenAtomFoundation/pika/pull/2430)\n- [Fixes the Issue of No Proper Response to Slave Synchronization Requests During Master Instance bgsave Execution](https://github.com/OpenAtomFoundation/pika/pull/2437)\n- [Fixes Data Inconsistency Issues When Applying Binlog on Slave Instances Without Locking the Operated Key](https://github.com/OpenAtomFoundation/pika/pull/2409)\n- [Fixes Data Inconsistency Issues After Data Migration](https://github.com/OpenAtomFoundation/pika/pull/2485)\n\n### 1.10 Test Suite Additions\n\nThe PikiwiDB (Pika) test suite consists of gtest unit tests, Redis TCL test suites, and Go test suites. In 3.5.3, we have added Codis cluster e2e tests.\n\nKey PRs:\n\n- [Pika TCL Test Suite](https://github.com/OpenAtomFoundation/pika/pull/2497)\n- [Pika Gotest Test Suite](https://github.com/OpenAtomFoundation/pika/pull/2502)\n\n### 1.11 Toolkit Additions\n\nPikiwiDB (Pika) has always valued the construction of toolkits, and all related tools can be found at https://github.com/OpenAtomFoundation/pika/tree/unstable/tools. In 3.5.3, we have added a new tool:\n\n- [PikiwiDB (Pika) Supports Large Key Analysis Tools](https://github.com/OpenAtomFoundation/pika/pull/2195)\n\n### 1.12 Documentation Updates\n\nThe PikiwiDB (Pika) documentation mainly consists of wiki documentation. In 3.5.3, we have updated the documentation for the Redis commands supported by Pika.\n\nDocumentation link: https://github.com/OpenAtomFoundation/pika/wiki/Pika-Supports-Redis-Interface-and-Content-Situation\n\n## 2 Release Improvements\n\nIn the first chapter, we described the main feature upgrades and improvements of version 3.5.3. Below is a detailed list of the relevant PRs for this release.\n\n### 2.1 New Features\n\n- [Pika Supports ACL](https://github.com/OpenAtomFoundation/pika/pull/2013)\n- [During Full-Quantity Replication, Pika Slave Nodes Do Not Accept Read Requests](https://github.com/OpenAtomFoundation/pika/pull/2197)\n- [Removes Residual Slot Code from Sharing Mode, Returns to v3.0, Where One Pika Instance Has Multiple DBs, Each with Only One Blackwidow](https://github.com/OpenAtomFoundation/pika/pull/2251)\n- [Automatically Recovers Service When Codis Dashboard Coroutine Panics](https://github.com/OpenAtomFoundation/pika/pull/2349)\n- [Pika Cache Adds New Bitmap Data Type](https://github.com/OpenAtomFoundation/pika/pull/2253)\n- [Pika Supports Separation of Fast and Slow Commands](https://github.com/OpenAtomFoundation/pika/pull/2162)\n- [Pika Exporter Exposes Cache-Related Data Collection Metrics](https://github.com/OpenAtomFoundation/pika/pull/2318)\n- [Pika Keeps Unix Timepoint After Completing Bgsave](https://github.com/OpenAtomFoundation/pika/pull/2167)\n- [Pika Supports Dynamic Configuration of disable_auto_compations Parameter](https://github.com/OpenAtomFoundation/pika/pull/2257)\n- [Pika Supports Redis Stream](https://github.com/OpenAtomFoundation/pika/pull/1955)\n- [Pika Supports Large Key Analysis Tools](https://github.com/OpenAtomFoundation/pika/pull/2195)\n- [Pika Supports Dynamic Adjustment of Pika Cache Parameters](https://github.com/OpenAtomFoundation/pika/pull/2197)\n- [Updates Pika Benchmark Tool to Support More Interface Pressure Tests](https://github.com/OpenAtomFoundation/pika/pull/2222)\n- [Pika Operator Supports Pika Cluster Auto-Scaling](https://github.com/OpenAtomFoundation/pika/pull/2121)\n- [Adds CompactRange Command to Support Compaction of a Specific Range of Keys](https://github.com/OpenAtomFoundation/pika/pull/2163)\n- [Improves Compaction Speed and Reduces Compaction Time](https://github.com/OpenAtomFoundation/pika/pull/2172)\n- [Upgrades RocksDB Version to v8.7.3](https://github.com/OpenAtomFoundation/pika/pull/2157)\n- [PikiwiDB (Pika) Distributed Cluster Codis Proxy Adds Observable Metrics](https://github.com/OpenAtomFoundation/pika/pull/2199)\n- [PikiwiDB (Pika) Distributed Cluster Supports Automatic Failover](https://github.com/OpenAtomFoundation/pika/pull/2386)\n- [Pika Supports Redis rename-command Feature](https://github.com/OpenAtomFoundation/pika/pull/2455)\n- [Optimizes Codis Slot Migration Speed, Supports Dynamic Adjustment of Migration Threads and Speed](https://github.com/OpenAtomFoundation/pika/pull/2486)\n- [PikiwiDB (Pika) Supports Dynamic Adjustment of max-conn-rbuf-size Parameter](https://github.com/OpenAtomFoundation/pika/pull/2434)\n- [Pika-Operator Supports Namespaces, Allows Deploying Different Clusters in Different Namespaces](https://github.com/OpenAtomFoundation/pika/pull/2480)\n- [Pika-Operator Supports Monitoring Metric Collection, Automatically Launches Pika-Exporter](https://github.com/OpenAtomFoundation/pika/pull/2451)\n- [ACL Backward Compatibility with Userblacklist](https://github.com/OpenAtomFoundation/pika/pull/2459)\n- [Enriches Pika TCL Test Suite](https://github.com/OpenAtomFoundation/pika/pull/2497)\n- [Enriches Pika Gotest Test Suite](https://github.com/OpenAtomFoundation/pika/pull/2502)\n\n### 2.2 Bug Fixes\n\n- [Fixes Issue of Incorrect Deletion of Dump Files During Full-Quantity Replication by Pika Slave Nodes](https://github.com/OpenAtomFoundation/pika/pull/2377)\n- [Fixes the Logic for Slave Nodes Receiving Exceptional Reply Packets from Masters During Full-Quantity Replication](https://github.com/OpenAtomFoundation/pika/pull/2319)\n- [Invokes Disable Compaction When Executing Shutdown Command, Enhances Exit Speed](https://github.com/OpenAtomFoundation/pika/pull/2345)\n- [Fixes Inaccurate Redis Memory Values in Codis-Dashboard](https://github.com/OpenAtomFoundation/pika/pull/2337)\n- [Optimizes INFO Command Latency, Reduces Frequency of Checking Disk Usage](https://github.com/OpenAtomFoundation/pika/pull/2197)\n- [Fixes Issue of Rsync Deleting Temporary Files with Incorrect Path, Leading to Failure in Opening RocksDB](https://github.com/OpenAtomFoundation/pika/pull/2186)\n- [Fixes Issue of Commands Not Specifying DB Name, Leading to Coredump of Some Commands](https://github.com/OpenAtomFoundation/pika/pull/2194)\n- [Uses info replication Command in Codis Dashboard Instead of info Command to Query Master IP, Reducing Performance Impact on Pika](https://github.com/OpenAtomFoundation/pika/pull/2198)\n- [Fixes Inconsistency Issues Between Cache and DB Data in Certain Scenarios](https://github.com/OpenAtomFoundation/pika/pull/2225)\n- [Fixes Issue of Segmentation Fault When Dump Directory is Empty](https://github.com/OpenAtomFoundation/pika/pull/2265)\n- [Fixes Issue of Certain Commands' Cache Not Taking Effect Due to Incorrect Flag Calculation](https://github.com/OpenAtomFoundation/pika/pull/2217)\n- [Fixes Issue of Slave Instances Being Inaccessible Due to Deadlock After Master Instance flushdb in Master-Slave Replication Mode](https://github.com/OpenAtomFoundation/pika/pull/2249)\n- [Fixes Issue of Commands Not Judging the Return Value of RocksDB](https://github.com/OpenAtomFoundation/pika/pull/2187)\n- [Standardizes Function Return Values and Initial Values](https://github.com/OpenAtomFoundation/pika/pull/2176)\n- [Fixes Inaccurate Network Monitoring Metric Statistics](https://github.com/OpenAtomFoundation/pika/pull/2234)\n- [Fixes Issue of Abnormal Parameters When Loading Configuration File](https://github.com/OpenAtomFoundation/pika/pull/2218)\n- [Fixes 100% CPU Usage Issue in Codis Dashboard](https://github.com/OpenAtomFoundation/pika/pull/2393)\n- [Fixes Issue of Abnormal Display of Pika Master-Slave Roles in Codis Front End](https://github.com/OpenAtomFoundation/pika/pull/2387)\n- [Fixes Data Inconsistency Issues After Data Migration](https://github.com/OpenAtomFoundation/pika/pull/2485)\n- [Fixes Issue of Inaccurate Display in Codis-dashboard After Scaling or Pod Start/Stop](https://github.com/OpenAtomFoundation/pika/pull/2475)\n- [Fixes Issue of Repeated Locking at the DB Level](https://github.com/OpenAtomFoundation/pika/pull/2372)\n- [Fixes Issue of Data Loss After Full-Quantity Replication Failure](https://github.com/OpenAtomFoundation/pika/pull/2439)\n- [Fixes Issue of No Proper Response to Slave Synchronization Requests During Master Instance bgsave Execution](https://github.com/OpenAtomFoundation/pika/pull/2437)\n- [Adds Data Synchronization Status During Full-Quantity Replication, Clarifying Data Synchronization Progress](https://github.com/OpenAtomFoundation/pika/pull/2430)\n- [Fixes Issue of No Locking of Operated Key When Applying Binlog on Slave Instances, Leading to Data Inconsistency](https://github.com/OpenAtomFoundation/pika/pull/2409)\n- [Fixes Issue of Master Instance Coredump During Codis Slot Migration](https://github.com/OpenAtomFoundation/pika/pull/2415)\n- [Fixes Issue of Deleting Dump Files in Use During Master-Slave Replication](https://github.com/OpenAtomFoundation/pika/pull/2377)\n- [Fixes Issue of Rsync Response Errors from Slave Instances During Master-Slave Replication](https://github.com/OpenAtomFoundation/pika/pull/2319)\n\n### 2.3 Release Tag\n\n[PikiwiDB (Pika) v3.5.3 Release Tag](https://github.com/OpenAtomFoundation/pika/releases/tag/v3.5.3)\n\n## 3 Community\n\nIf you have any questions, feel free to join our community discussion group. The PikiwiDB (Pika) open-source community appreciates your support and help.\n\n* telegram https://t.me/+gMlTzNacOF1iMTM1\n* WeChat Assistant \"PikiwiDB\""},{"id":"Pika-3.5.3","metadata":{"permalink":"/blog/Pika-3.5.3","source":"@site/blog/2024-03-27-Pika-3.5.3.md","title":"What's new in Pika v3.5.3 ","description":"随着 Redis 宣布采用双协议以维护其商业利益，PikiwiDB(Pika) 社区非常荣幸地宣布之际，我们的最新 v3.5.3 正式生产可用版本现已发布。","date":"2024-03-27T00:00:00.000Z","tags":[],"readingTime":14.775,"hasTruncateMarker":false,"authors":[{"name":"360 中间件团队","title":"Pika 开源社区"}],"frontMatter":{"title":"What's new in Pika v3.5.3 ","slug":"Pika-3.5.3","authors":[{"name":"360 中间件团队","title":"Pika 开源社区"}],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"What's new in Pika v3.5.3 （英文版本）","permalink":"/blog/Pika-3.5.3-en"},"nextItem":{"title":"What's new in Pika v3.5.2","permalink":"/blog/Pika-3.5.2"}},"content":"随着 Redis 宣布采用双协议以维护其商业利益，PikiwiDB(Pika) 社区非常荣幸地宣布之际，我们的最新 v3.5.3 正式生产可用版本现已发布。\n\nv3.5.3 版本不仅修复了长期存在的 Bug，还引入了一系列新特性。这些新特性包括 Pika 对 ACL 的支持、移除了 Sharing 模式的残留 Slot 代码、命令执行的快慢分离、Redis Stream 支持、大 key 分析工具、以及 Pika 分布式集群的全自动化 failover 等。此外，我们在 3.5.3 版本中增加了更多的自动化测试用例，以提高 Pika 服务的稳定性和健壮性，确保用户能够享受到更高效、更稳定的使用体验。本文将详细介绍本次更新的主要功能、Bug 修复和性能提升。\n\n在深入探讨 3.5.3 版本的更新内容之前，请注意以下几点声明：\n\n1. 由于商标问题，Pika 项目已更名为 PikiwiDB。在本文中，我们将使用 PikiwiDB(Pika) 来指代项目，项目地址为：https://github.com/OpenAtomFoundation/pika\n2. 我们创建了一个新项目 https://github.com/OpenAtomFoundation/pikiwidb，这是一个基于 Raft 协议实现的兼容 Redis 协议的大容量 KV 数据库，主要面向强一致性数据场景，例如存储约 10TiB 规模的元数据。PikiwiDB 将专门用于指代此项目。\n3. 我们为 PikiwiDB 设计了一个新的 logo，作为其商标，并已在相关政府机构注册。\n\n![](https://github.com/OpenAtomFoundation/pikiwidb/blob/unstable/docs/images/pikiwidb-logo.png)\n\n## 1 主要更新\n\n### 1.1 支持 ACL\n\nPikiwiDB(Pika) 3.5.3 版本正式全面支持 Redis ACL，为未来在云原生 Pika 集群中支持多租户场景奠定了基础。在此之前，Pika 已经支持了 Redis 的用户认证方式，如 auth/userpass/requirepass，以及通过 pika.conf 中的 userblacklist 配置命令黑名单模式。本次更新保持了向后兼容，并支持这些已有的使用方式。\n\n我们还确保 PikiwiDB(Pika) 的 ACL 实现与 Redis ACL 完全兼容，通过将 Redis 的所有 ACL TCL 测试集纳入 PikiwiDB(Pika) 的测试集中。\n\n关键 PR 链接：\n\n- [PikiwiDB(Pika) 支持 ACL](https://github.com/OpenAtomFoundation/pika/pull/2013)\n- [修正 ACL 用户认证错误问题](https://github.com/OpenAtomFoundation/pika/pull/2449)\n- [ACL 向前兼容 userblacklist](https://github.com/OpenAtomFoundation/pika/pull/2459)\n- [添加 Redis ACL 测试集](https://github.com/OpenAtomFoundation/pika/pull/2495)\n\n### 1.2 混合存储模型支持 bitmap\n\n在单体环境下，同时优化 PikiwiDB(Pika) 的读/写/compaction 是一项挑战。在 v3.5.2 版本中，我们引入了由缓存 Redis 和 RocksDB 构成的混合存储模型，并支持了 string/list/set/zset/hashtable 五种数据结构。在 3.5.3 版本中，我们增加了对 bitmap 的支持。\n\n此外，我们在 3.5.3 版本中支持对 Redis 缓存进行动态参数调整。\n\n关键 PR 链接：\n\n- [PikiwiDB(Pika) 支持 bitmap](https://github.com/OpenAtomFoundation/pika/pull/2253)\n- [支持对 Redis 缓存进行动态调参](https://github.com/OpenAtomFoundation/pika/pull/2197)\n\n### 1.3 快慢命令分离\n\n为了避免慢命令阻塞快命令的执行，我们在 Codis-Proxy 和 PikiwiDB(Pika) 两个层面实现了快慢命令分离。\n\n关键 PR 链接：\n\n- [实现快慢命令分离](https://github.com/OpenAtomFoundation/pika/pull/2162)\n\n### 1.4 Redis Stream 支持\n\n虽然 PikiwiDB(Pika) 之前支持了 Redis pubsub，但它只能进行在线消息传递。在 3.5.3 版本中，我们增加了对 Redis Stream 的有限支持，类似于消息队列（MQ），以便更安全地传递消息。为了确保数据的安全性，我们在底层引擎 BlackWidow 中特别添加了对 Stream 数据类型的支持。\n\n关键 PR 链接：\n\n- [Pika 支持 Redis Stream](https://github.com/OpenAtomFoundation/pika/pull/1955)\n\n请注意，Pika Stream 目前还不支持消费组消费，这将在后续版本中实现。\n\n### 1.5 云原生集群\n\n在 PikiwiDB(Pika) 3.5.0 版本中，我们开源了 Pika-Operator，它支持在 K8s 上部署 Pika 主从对。在 3.5.2 版本中，我们基于 Kubeblocks 的 Pika-Operator 支持了在 K8s 上部署类似 Codis 的 Pika Cluster，但当时还不支持动态扩缩容。\n\n在 3.5.3 版本中，最新的 Pika-Operator 已经支持了 Codis Group 级别的节点扩缩容，并且支持数据的 Rebalance。\n\n关键 PR 链接：\n\n- [Pika-Operator 支持 Pika 集群自动扩容](https://github.com/OpenAtomFoundation/pika/pull/2121)\n- [优化 codis slot 迁移速度，支持动态修改迁移线程和速度](https://github.com/OpenAtomFoundation/pika/pull/2486)\n- [Pika-operator 支持 namespace，可在不同 namespace 下部署不同的集群](https://github.com/OpenAtomFoundation/pika/pull/2480)\n- [Pika-operator 支持监控指标采集，自动拉起 pika-expoter](https://github.com/OpenAtomFoundation/pika/pull/2451)\n\n### 1.6 Compaction 优化\n\nPikiwiDB(Pika) 的底层磁盘存储引擎 RocksDB 在进行 compaction 时会显著影响 PikiwiDB(Pika) 的读写性能。因此，控制好 compaction 是优化 Pika 读写性能的关键。\n\n关键 PR 链接：\n\n- [添加 CompactRange 命令，支持对一定范围内的 key 进行 compact](https://github.com/OpenAtomFoundation/pika/pull/2163)\n- [提升 Compaction 速度，减少 Compaction 耗时](https://github.com/OpenAtomFoundation/pika/pull/2172)\n- [执行 shutdown 命令时调用 disable compaction，提升进程退出速度](https://github.com/OpenAtomFoundation/pika/pull/2345)\n\n### 1.7 自动 Failover\n\nPikiwiDB(Pika) 集群目前是基于 Codis 实现的。为了提高基于 Codis 的 PikiwiDB(Pika) Cluster 的易用性，我们对 Codis 进行了许多扩展。\n\n原始的 Codis 不支持 Group 内的 Failover，需要使用 Redis Sentinel，这会导致运维成本增加。我们在 Codis Dashboard 中加入了 sentinel 的功能，实现了对 Group 内主从的自动 failover。\n\n关键 PR 链接：\n\n- [PikiwiDB(Pika) 分布式集群支持自动 failover](https://github.com/OpenAtomFoundation/pika/pull/2386)\n\n### 1.8 可观测性提升\n\nPikiwiDB(Pika) 的可观测性关键组件是 Pika-Exporter。在 3.5.2 版本中，我们虽然添加了 Redis Cache 缓存热数据，但缺少监控指标。在 3.5.3 版本中，我们增加了包括命中率、每秒命中次数、Redis Cache 内存使用量、Redis Cache 个数、Redis Cache DB 个数 等指标。\n\n关键 PR 链接：\n\n- [Pika exporter 暴露 cache 相关的数据采集指标](https://github.com/OpenAtomFoundation/pika/pull/2318)\n- [PikiwiDB(Pika) 分布式集群 Codis proxy 新增可观测指标](https://github.com/OpenAtomFoundation/pika/pull/2199)\n- [修复 dbsize 计算错误问题](https://github.com/OpenAtomFoundation/pika/pull/2494)\n- [修复网络监控指标统计不准确的问题](https://github.com/OpenAtomFoundation/pika/pull/2234)\n\n### 1.9 数据一致性\n\n3.5.3 版本修复了许多 PikiwiDB(Pika) 主从同步问题，确保数据的一致性。\n\n关键 PR 链接：\n\n- [修复主从复制过程中，slave 节点收到 master 异常回包后的处理逻辑](https://github.com/OpenAtomFoundation/pika/pull/2319)\n- [修复 Pika cache 部分场景下 cache 和 DB 数据不一致的问题](https://github.com/OpenAtomFoundation/pika/pull/2225)\n- [修复全量复制失败后，未做处理导致数据丢失问题](https://github.com/OpenAtomFoundation/pika/pull/2439)\n- [修复主从复制过程中，主实例执行 bgsave 过程中，没有正确回应从的同步请求](https://github.com/OpenAtomFoundation/pika/pull/2437)\n- [全量复制过程中，添加数据同步状态，明确数据同步进度](https://github.com/OpenAtomFoundation/pika/pull/2430)\n- [修复从库在 Apply binlog 时，没有对操作的 key 加锁，导致数据不一致的问题](https://github.com/OpenAtomFoundation/pika/pull/2409)\n- [修复迁移数据后数据不一致的问题](https://github.com/OpenAtomFoundation/pika/pull/2485)\n\n### 1.10 测试集增加\n\nPikiwiDB(Pika) 的测试集由 gtest 单测、Redis TCL 测试集和 Go 测试集组成。在 3.5.3 版本中，我们增加了 Codis 集群 e2e 测试。\n\n关键 PR 链接：\n\n- [Pika TCL 测试集](https://github.com/OpenAtomFoundation/pika/pull/2497)\n- [Pika Gotest 测试集](https://github.com/OpenAtomFoundation/pika/pull/2502)\n\n### 1.11 工具集更新\n\nPikiwiDB(Pika) 一直重视工具集的建设，所有相关工具都可以在 https://github.com/OpenAtomFoundation/pika/tree/unstable/tools 中找到。在 3.5.3 版本中，我们新增了一个工具：\n\n- [PikiwiDB(Pika) 支持大 key 分析工具](https://github.com/OpenAtomFoundation/pika/pull/2195)\n\n### 1.12 文档更新\n\nPikiwiDB(Pika) 的文档主要是 wiki 文档。在 3.5.3 版本中，我们更新了 Pika 支持的 Redis 命令文档。\n\n文档链接：https://github.com/OpenAtomFoundation/pika/wiki/pika-%E6%94%AF%E6%8C%81%E7%9A%84redis%E6%8E%A5%E5%8F%A3%E5%8F%8A%E5%85%BC%E5%AE%B9%E6%83%85%E5%86%B5\n\n## 2 发版详情\n\n在第一章节中，我们概述了 3.5.3 版本的主要功能升级和改进。下面详细列出了本次发版的相关 PR。\n\n### 2.1 新特性\n\n- [Pika 支持 ACL](https://github.com/OpenAtomFoundation/pika/pull/2013)\n- [在全量复制过程中，pika 服务的从节点不接收读请求](https://github.com/OpenAtomFoundation/pika/pull/2197)\n- [删除 Sharing 模式残留的 Slot 代码，回归 3.0，以后一个 Pika 下有多个 DB，每个 DB 只有一个 Blackwidow](https://github.com/OpenAtomFoundation/pika/pull/2251)\n- [在 Codis dashboard 协程 panic 时自动恢复服务](https://github.com/OpenAtomFoundation/pika/pull/2349)\n- [Pika cache 新增 bimap数据类型](https://github.com/OpenAtomFoundation/pika/pull/2253)\n- [Pika 支持快慢命令分离](https://github.com/OpenAtomFoundation/pika/pull/2162)\n- [Pika exporter 暴露 cache 相关的数据采集指标](https://github.com/OpenAtomFoundation/pika/pull/2318)\n- [Pika 执行完成 Bgsave 后, 保留 unix timepoint](https://github.com/OpenAtomFoundation/pika/pull/2167)\n- [Pika 支持动态配置 disable_auto_compations 参数](https://github.com/OpenAtomFoundation/pika/pull/2257)\n- [Pika 支持 Redis Stream](https://github.com/OpenAtomFoundation/pika/pull/1955)\n- [Pika 支持大 key 分析工具](https://github.com/OpenAtomFoundation/pika/pull/2195)\n- [Pika 支持动态调整 Pika cache 参数](https://github.com/OpenAtomFoundation/pika/pull/2197)\n- [更新 Pika benchmark 工具支持更多的接口压测](https://github.com/OpenAtomFoundation/pika/pull/2222)\n- [Pika Operator 支持 Pika 集群自动扩容](https://github.com/OpenAtomFoundation/pika/pull/2121)\n- [添加 CompactRange 命令支持对一定范围内的 key 进行 compact](https://github.com/OpenAtomFoundation/pika/pull/2163)\n- [提升 Compaction 速度减少 Compaction 耗时](https://github.com/OpenAtomFoundation/pika/pull/2172)\n- [升级 RocksDB 版本到 v8.7.3](https://github.com/OpenAtomFoundation/pika/pull/2157)\n- [Pika 分布式集群 Codis proxy 新增可观测指标](https://github.com/OpenAtomFoundation/pika/pull/2199)\n- [Pika 分布式集群支持自动 failover](https://github.com/OpenAtomFoundation/pika/pull/2386)\n- [Pika 支持 redis rename-command 功能](https://github.com/OpenAtomFoundation/pika/pull/2455)\n- [优化 codis slot 迁移速度，支持动态修改迁移线程和速度](https://github.com/OpenAtomFoundation/pika/pull/2486)\n- [Pika 支持动态调整 max-conn-rbuf-size 参数](https://github.com/OpenAtomFoundation/pika/pull/2434)\n- [Pika-operator 支持 namespace，可以在不同的 namespace 下部署不同的集群](https://github.com/OpenAtomFoundation/pika/pull/2480)\n- [Pika-operator 支持监控指标采集，自动拉起 pika-expoter](https://github.com/OpenAtomFoundation/pika/pull/2451)\n- [ACL 向前兼容 userblacklist](https://github.com/OpenAtomFoundation/pika/pull/2459)\n- [丰富了 Pika TCL 测试集](https://github.com/OpenAtomFoundation/pika/pull/2497)\n- [丰富了 Pika Gotest 测试集](https://github.com/OpenAtomFoundation/pika/pull/2502)\n\n### 2.2 Bug 修复\n\n- [修复 Pika 有从节点进行全量复制期间会误删除 dump 文件的问题](https://github.com/OpenAtomFoundation/pika/pull/2377)\n- [修复主从复制过程中, slave 节点收到 master 异常回包后的处理逻辑](https://github.com/OpenAtomFoundation/pika/pull/2319)\n- [在 Pika 执行 shutdown 命令时调用 disable compaction, 提升进程退出速度](https://github.com/OpenAtomFoundation/pika/pull/2345)\n- [修复 Codis-dashboard Redis Memory 值不准确的问题](https://github.com/OpenAtomFoundation/pika/pull/2337)\n- [INFO 命令耗时优化，降低查磁盘使用量的频率](https://github.com/OpenAtomFoundation/pika/pull/2197)\n- [修复 Rsync 删除临时文件路径不对，删除失败，导致rocksdb打开失败的问题](https://github.com/OpenAtomFoundation/pika/pull/2186)\n- [修复 Compact, Bgsave, Info keyspace 命令未指定db名称，导致部分命令 coredump 的问题](https://github.com/OpenAtomFoundation/pika/pull/2194)\n- [Codis dashboard 用 info replication 替代 info 命令查寻 master ip 降低对 Pika 的性能影响](https://github.com/OpenAtomFoundation/pika/pull/2198)\n- [修复 Pika cache 使用边缘case，解决部分场景下 cache 和 DB 数据不一致的问题](https://github.com/OpenAtomFoundation/pika/pull/2225)\n- [修复当 dump 文件夹为空时，会启动报错 Segmentation fault 的问题](https://github.com/OpenAtomFoundation/pika/pull/2265)\n- [修复因为 flag 计算错误，导致的部分命令缓存没有生效问题](https://github.com/OpenAtomFoundation/pika/pull/2217)\n- [修复主从复制模式下，主实例 flushdb 后，从实例因为死锁导致的不能访问的问题](https://github.com/OpenAtomFoundation/pika/pull/2249)\n- [修复部分命令未对 RocksDB 的返回值进行判断的问题](https://github.com/OpenAtomFoundation/pika/pull/2187)\n- [规范函数的返回值及初始值](https://github.com/OpenAtomFoundation/pika/pull/2176)\n- [修复网络监控指标统计不准确的问题](https://github.com/OpenAtomFoundation/pika/pull/2234)\n- [修复配置文件加载部分参数异常的问题](https://github.com/OpenAtomFoundation/pika/pull/2218)\n- [修复 Codis dashboard cpu 100% 的问题](https://github.com/OpenAtomFoundation/pika/pull/2393)\n- [修复 Codis fe pika 主从角色显示异常的问题](https://github.com/OpenAtomFoundation/pika/pull/2387)\n- [修复迁移数据后数据不一致的问题](https://github.com/OpenAtomFoundation/pika/pull/2485)\n- [修复 dbsize 计算错误问题](https://github.com/OpenAtomFoundation/pika/pull/2494)\n- [修复扩缩容或者 pod 起停后，Codis-dashboard 界面显示不准确的问题](https://github.com/OpenAtomFoundation/pika/pull/2475)\n- [修复 DB 层重复上锁的问题](https://github.com/OpenAtomFoundation/pika/pull/2372)\n- [修复全量复制失败后，未做处理导致数据丢失问题](https://github.com/OpenAtomFoundation/pika/pull/2439)\n- [修复主从复制过程中，主实例执行 bgsave 过程中，没有正确回应从的同步请求](https://github.com/OpenAtomFoundation/pika/pull/2437)\n- [全量复制过程中，添加数据同步状态，明确数据同步进度](https://github.com/OpenAtomFoundation/pika/pull/2430)\n- [修复从库在 Apply binlog 时，没有对操作的 key 加锁，导致数据不一致的问题](https://github.com/OpenAtomFoundation/pika/pull/2409)\n- [修复 codis slot 迁移过程中 master 实例 coredump 的问题](https://github.com/OpenAtomFoundation/pika/pull/2415)\n- [修复在主从复制过程中，删除正在使用的 dump 文件的问题](https://github.com/OpenAtomFoundation/pika/pull/2377)\n- [修复主从复制过程中从实例 rsync 响应错误的问题](https://github.com/OpenAtomFoundation/pika/pull/2319)\n\n### 2.3 发版标签\n\nhttps://github.com/OpenAtomFoundation/pika/releases/tag/v3.5.3\n\n## 3 社区\n\nPikiwiDB(Pika) 开源社区感谢您的支持，如果您有任何疑问或建议，欢迎加入我们的社区交流群：\n\n* 微信助手 PikiwiDB【请在微信中搜索 PikiwiDB】\n* telegram 群 https://t.me/+gMlTzNacOF1iMTM1"},{"id":"Pika-3.5.2","metadata":{"permalink":"/blog/Pika-3.5.2","source":"@site/blog/2023-12-03-Pika-3.5.2.md","title":"What's new in Pika v3.5.2","description":"Pika 社区近期发布了备受期待的 v3.5.2 版本 https://github.com/OpenAtomFoundation/pika/releases/tag/v3.5.2-alpha ，不仅解决了历史遗留的 Bug 问题，还引入了多项新特性。这些新特性主要包括 Pika 支持 Redis 事务、Pika 上层增加缓存层实现冷热数据分离、提升读性能、Codis-Proxy 支持动态修改配置参数等等，无疑将会让用户感受到更为高效和稳定的使用体验。","date":"2023-12-03T00:00:00.000Z","tags":[],"readingTime":2.575,"hasTruncateMarker":false,"authors":[{"name":"于雨","title":"dubbo-go开源社区"}],"frontMatter":{"title":"What's new in Pika v3.5.2","slug":"Pika-3.5.2","authors":[{"name":"于雨","title":"dubbo-go开源社区"}],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"What's new in Pika v3.5.3 ","permalink":"/blog/Pika-3.5.3"},"nextItem":{"title":"What's new in Pika v3.5.1","permalink":"/blog/Pika-3.5.1"}},"content":"Pika 社区近期发布了备受期待的 v3.5.2 版本 https://github.com/OpenAtomFoundation/pika/releases/tag/v3.5.2-alpha ，不仅解决了历史遗留的 Bug 问题，还引入了多项新特性。这些新特性主要包括 Pika 支持 Redis 事务、Pika 上层增加缓存层实现冷热数据分离、提升读性能、Codis-Proxy 支持动态修改配置参数等等，无疑将会让用户感受到更为高效和稳定的使用体验。\n\n## 新特性\n\n+ Pika 支持 Redis 事务，使得 Pika 的数据够在一系列命令的执行中保持数据的一致性和可靠性。 https://github.com/OpenAtomFoundation/pika/pull/2124\n+ Pika 上层增加缓存层实现冷热数据分离，提升读性能。 https://github.com/OpenAtomFoundation/pika/pull/2171\n+ Codis-Proxy 支持动态修改配置参数，方便我们做参数调整。 https://github.com/OpenAtomFoundation/pika/pull/2110\n+ 补全 Go Test 测试用例。 https://github.com/OpenAtomFoundation/pika/pull/2082\n+ CI 增加 cache 提升编译速度。 https://github.com/OpenAtomFoundation/pika/pull/2093\n+ 增加 redis-copy 流量复制工具。 https://github.com/OpenAtomFoundation/pika/pull/2060\n\nbugfix\n\n+ 修复 pika 在使用 SETRANGE 命令出现 coredump 的问题。 https://github.com/OpenAtomFoundation/pika/pull/2141\n+ 修复因删除 Clearreplicationid 写进 binlog 导致的全量复制问题。 https://github.com/OpenAtomFoundation/pika/pull/2135\n+ 修改锁粒度，提升 pika 写 binlog 的性能。 https://github.com/OpenAtomFoundation/pika/pull/2129\n+ 修复复杂数据类型成员变量可能出现数据溢出。 https://github.com/OpenAtomFoundation/pika/pull/2106\n+ 修复 decr 命令返回值错误问题。 https://github.com/OpenAtomFoundation/pika/pull/2092\n+ 修复 setrange 和 setbit 命令没有保留原 key 的过期时间的问题。 https://github.com/OpenAtomFoundation/pika/pull/2095\n\n下期版本规划\n\n预计再过两个月左右，我们会在农历新年前发布  3.5.3  版本，相关关键特性有：\n\n+ Pika 通过快慢命令分离提升读写性能。 https://github.com/OpenAtomFoundation/pika/pull/2162\n+ 支持 Redis ACL，在 Pika 中引入用户概念，进行权限控制。 https://github.com/OpenAtomFoundation/pika/pull/2013\n+ 支持 Redis Stream，实现消息队列。 https://github.com/OpenAtomFoundation/pika/pull/1955\n+ 添加 Pika 特有命令 compactrange，对指定范围内的 key 进行 compact   以解决大 key 删除时读放大的问题。 https://github.com/OpenAtomFoundation/pika/pull/2163\n+ 支持 lastsave 指令。 https://github.com/OpenAtomFoundation/pika/pull/2167\n\n感谢大家对 Pika 开源公众号的关注 ，Pika 3.5 版本重大特性及使用规范我们会在稍后的文章中进行介绍，我们下期再见～\n\n![2023-09-28-Pika-3.5.2-connect](2023-12-03-Pika-3.5.2-connect.png)"},{"id":"Pika-3.5.1","metadata":{"permalink":"/blog/Pika-3.5.1","source":"@site/blog/2023-09-28-Pika-3.5.1.md","title":"What's new in Pika v3.5.1","description":"Pika 社区很高兴宣布，我们今天发布已经过我们生产环境验证 v3.5.1 版本 https://github.com/OpenAtomFoundation/pika/releases/tag/v3.5.1 。","date":"2023-09-28T00:00:00.000Z","tags":[],"readingTime":4.385,"hasTruncateMarker":false,"authors":[{"name":"于雨","title":"dubbo-go开源社区"}],"frontMatter":{"title":"What's new in Pika v3.5.1","slug":"Pika-3.5.1","authors":[{"name":"于雨","title":"dubbo-go开源社区"}],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"What's new in Pika v3.5.2","permalink":"/blog/Pika-3.5.2"},"nextItem":{"title":"What's new in Pika v3.5.0","permalink":"/blog/Pika-3.5.0"}},"content":"Pika 社区很高兴宣布，我们今天发布已经过我们生产环境验证 v3.5.1 版本 https://github.com/OpenAtomFoundation/pika/releases/tag/v3.5.1 。\n\n该版本不仅做了很多优化工作，还引入了多项新功能。这些新功能包括 动态关闭 WAL、ReplicationID 检测是否增量复制、在 K8s 环境上 Pika 服务的自动注册从而实现集群的自组织、以及 exporter 检测集群指标等等，无疑将会让用户享受到更为稳定和高效的 NoSQL 使用体验。\n\n## 新特性\n\n+ 1 Slow log 增加队列等待时间统计，在队列阻塞的时候方便我们进行问题定位。PR 1997， 作者 wangshao1。\n+ 2 主从复制使用 ReplicationID 判断是否进行增量同步，解决原主从同步方式切主后整个数据集会进行全量复制的问题，可以提升 Pika 性能。PR 1951， 作者 Mixficsol。\n+ 3 WAL 以 'disablewal' 命令方式支持动态关闭，在写性能遇到瓶颈的时候，可以通过命令关闭 WAL  缓解写性能下降的问题，关闭 WAL 有机器宕机后丢失数据的风险，用户需要根据自己的使用习惯权衡。PR 2015，作者 Mixficsol。\n+ 4 flush 线程数和 compaction 线程数合二为一，在 Compaction 性能瓶颈时，可以动态调整线程数，缓解 Comapction 损耗 Pika 性能的问题。PR 2014， 作者 Tianpingan。\n+ 5 升级了 RocksDB 版本到 v8.3.3。PR 2000， 作者 dingxiaoshuai123。\n+ 6 新增周期性打印工作队列的长度功能，在队列阻塞的时候可以快速定位问题。PR 1978， 作者 Tianpingan。\n+ 7 新增利用一个 pika_exporter 监测整个集群的指标，实现一个 Pika Exporter 实例监控整个集群，解决了 3.5.0 版本一个 Pika Exporter  监测一个 Pika 实例消耗资源的问题。PR 1953， 作者 chenbt-hz。\n+ 8 实现在  K8s  环境上  Pika  服务的自动注册，在启动时自动注册，从而实现集群的自组织 ，实现了通过命令拉起整个 Pika Cluster 集群。PR 1931， 作者 machinly。\n\n## 2 bug 修复\n\n+ 1 调整了 Rate_limit 参数，修复了压测时出现 RPS 为 0 的情况 。PR 2009， 作者 Mixficsol。\n+ 2 修复了 INFODATA 命令中对于遍历数据文件时出现空路径的逻辑判断。PR 1996， 作者 Mixficsol。\n+ 3 修复了 Codis 在线上出现大毛刺的问题。PR 2016， 作者 chejinge。\n+ 4 修复了 macOS 环境下编译使用 tools 导致编译不过的问题 。PR 2011， 作者 A2ureStone。\n+ 5 减少了 exporter 非必要日志的打印，降低 了资源利用率。PR 1945， 作者 Mixficsol。\n\n## 3 使用建议\n\n本次新增了几个配置参数，大家在使用过程中，需要根据使用情况按需调整：\n\n+ 1 max-rsync-parallel-num：主从全量复制线程数，需要根据自己机器 CPU 核数和部署实例个数进行调整，建议最小设置为 2。\n+ 2 rate-limiter-bandwidth: 限制 RocksDB 数据库读写速度，限制数据库在一定时间内可以读写的数据量，默认 2000MiB/s，需要根据自己的机器性能和部署实例做调整。\n+ max-background-jobs: compaction 和 flushdb 线程数，要根据自己机器 CPU 核数和部署实例个数进行调整，建议最小设置为 4。\n+ 3 throttle-bytes-per-second: 主从复制传输限速参数，默认为 200MiB/s，该参数可以根据机器网卡的配置及部署 pika 实例的个数进行调整。\n\n![2023-09-28-Pika-3.5.1-connect.png](2023-09-28-Pika-3.5.1-connect.png)"},{"id":"Pika-3.5.0","metadata":{"permalink":"/blog/Pika-3.5.0","source":"@site/blog/2023-08-25-Pika-3.5.0.md","title":"What's new in Pika v3.5.0","description":"时隔两年，Pika 社区正式发布经由社区 50 多人参与开发并在 360 生产环境验证可用的 v3.5.0 版本，新版本在提升性能的同时，也支持了 Codis 集群部署，BlobDB KV 分离，增加 Exporter 等新特性。","date":"2023-08-25T00:00:00.000Z","tags":[],"readingTime":9.825,"hasTruncateMarker":false,"authors":[{"name":"于雨","title":"dubbogo示土区"}],"frontMatter":{"title":"What's new in Pika v3.5.0","slug":"Pika-3.5.0","authors":[{"name":"于雨","title":"dubbogo示土区"}],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"What's new in Pika v3.5.1","permalink":"/blog/Pika-3.5.1"},"nextItem":{"title":"Pika Blackwidow 引擎数据存储格式","permalink":"/blog/pika-blackwidow"}},"content":"时隔两年，Pika 社区正式发布经由社区 50 多人参与开发并在 360 生产环境验证可用的 v3.5.0 版本，新版本在提升性能的同时，也支持了 Codis 集群部署，BlobDB KV 分离，增加 Exporter 等新特性。\n\n我们将详细介绍该版本引入的重要新特性。\n\n##  1 去除 Rsync\n\n在 v3.5.0 版本之前，Pika 使用 Rsync 工具进行引擎中存量数据的同步，Pika 进程启动时创建 Rsync 子进程。这种同步方式在实际使用中出现了一些问题，包括Pika 进程 crash 后重新拉起无法正常同步以及同步过程中 Rsync 进程无故退出等。在今年发布的 v3.5.0 版本中，我们在全量同步方案方面进行了重要的改进，摒弃了以往使用的 Rsync，实现了全新的数据同步方案，支持了断点续传，动态调节传输限速等特性，以确保同步过程更加稳定、可控。这些改进不仅增强了同步的可靠性，还为用户提供了更好的使用体验。\n\n+ 去除 Rsync 进程，使用自研全量同步方式\n  https://github.com/OpenAtomFoundation/pika/pull/1805\n\n+ 实现断点续传，传输限速功能\n  https://github.com/OpenAtomFoundation/pika/pull/1926\n\n+ Pika 主从同步时，进行 master run_id 的检验\n  https://github.com/OpenAtomFoundation/pika/pull/1805\n\n## 2 兼容更多 Redis 命令\n\n在 v3.5.0 版本中，我们迈出了更大的一步，提升了对 Redis 命令的兼容性，对 Redis 命令提供了更广泛的支持。这个版本的改进使得 Pika 在与 Redis 生态系统的集成中表现更加出色，为用户提供了更丰富的功能和更广阔的可能性。我们对命令支持的扩展，为用户提供了更多的灵活性，以满足不同场景下的需求。\n\n+ 支持 UNLINK 命令\n  https://github.com/OpenAtomFoundation/pika/pull/1273\n+ 支持 INFO COMMANDSTATS 命令\n  https://github.com/OpenAtomFoundation/pika/pull/1660\n+ 支持 HELLO、SETNAME 命令\n  https://github.com/OpenAtomFoundation/pika/pull/1245\n+ 支持 BLPOP、BRPOP 命令\n  https://github.com/OpenAtomFoundation/pika/pull/1548\n+ 新增 Pika 原创 DISKRECOVERY 命令\n  https://github.com/OpenAtomFoundation/pika/pull/1843\n\n## 3 RocksDB 版本升级和分级压缩\n\n在 v3.5.0 版本中，我们进行了一项重要的升级，将 RocksDB 引擎升级至 v8.1.1 版本，并实现了分级压缩功能的整合。这一升级不仅是技术的飞跃，也是我们对系统性能和优化的持续关注的体现。通过这项升级，我们为 Pika 增加了更高级别的数据管理能力，同时也让系统更好地适应不同的压缩需求，为用户的数据存储和检索提供了更大的灵活性和效率。\n\n+ 升级 RocksDB 版本到 v8.1.1\n  https://github.com/OpenAtomFoundation/pika/pull/1396\n+ 实现 RocksDB 分级压缩\n  https://github.com/OpenAtomFoundation/pika/pull/1365\n+ 新增 RocksDB 缓存配置项 num-shard-bits 能够从配置文件中读取\n  https://github.com/OpenAtomFoundation/pika/pull/1189\n\n## 4 支持 BlobDB\n\n在 v3.5.0 版本中，我们引入了引人瞩目的创新--对 BlobDB 和 KV 存储层进行了分离，为我们的系统注入了新的活力。这个版本的升级使得 Pika 在数据存储方面更加灵活和高效。我们通过支持 BlobDB KV 分离，提供了更优化的数据存储结构，为用户的数据管理和查询操作带来了更深层次的优势。这一重要改进将在更多应用场景下展现出其强大的潜力。\n\n+ 支持 BlobDB KV 分离\n  https://github.com/OpenAtomFoundation/pika/pull/1456\n\n## 5 基于 Codis 的集群模式\n\n在 v3.5.0 版本中，我们积极引入了 Codis 集群模式，此外，我们不仅仅将 Codis 集群模式融入了系统中，还为其提供了迁移 slot 的命令支持，从而实现了更加智能化的集群管理。这一重大变革不仅扩展了 Pika 在大规模数据存储场景中的应用范围，还进一步提升了系统的可扩展性和高可用性。通过引入 Codis 集群模式，我们对用户的数据处理和管理提供了更优化的解决方案。\n\n+ 引入 Codis 到 Pika\n\n    https://github.com/OpenAtomFoundation/pika/pull/1279\n\n+ 引入 Codis 的 CI\n\n    https://github.com/OpenAtomFoundation/pika/pull/1311\n\n+ 支持 Codis 迁移 slot 命令\n\n    https://github.com/OpenAtomFoundation/pika/pull/1632\n\n+ 新增是否在 reload 的 slotmigrate 状态\n\n    https://github.com/OpenAtomFoundation/pika/pull/1700\n\n## 6 可观测性\n\n在 v3.5.0 版本中，我们引入了一个创新性的工具--pika_exporter，以提升对 Pika 数据库的可观测性。这一工具的加入不仅是对我们对系统监测能力的持续增强的反映。而在版本的后续更新中，我们进一步充实了指标，不断丰富了 Pika 的可观测性。为用户提供了更为全面和精准的数据洞察力。\n\n+ 新增 Pika 可观测系统 pika_exporter\n\n    https://github.com/OpenAtomFoundation/pika/pull/1388\n\n+ 新增网络 I/O 流量监控指标\n\n    https://github.com/OpenAtomFoundation/pika/pull/1733\n\n+ 新增命令统计耗时指标\n\n    https://github.com/OpenAtomFoundation/pika/pull/1751\n\n+ 新增 estimate_pending_compaction_bytes 度量来分析碎片率指标\n\n    https://github.com/OpenAtomFoundation/pika/pull/1736\n\n+ 新增 RocksDB 指标\n\n    https://github.com/OpenAtomFoundation/pika/pull/1560\n\n## 7 容器化部署\n\n在 v3.5.0 版本中，我们引入了一个具有创新意义的里程碑--pika-operator mvp 版本，这一版本在技术上实现了一个重要目标：将 Pika 单实例服务迁移到 Kubernetes（K8s）平台上的快速部署。这不仅是对我们持续关注行业发展的体现，也是我们不断提升用户体验的追求。通过 pika-operator，我们为用户提供了更便捷的部署方案，将 Pika 的高性能数据库引擎与 Kubernetes 的灵活性相融合，从而为用户的应用环境带来更高效、更弹性的支持。\n\n+ 实现 Pika 单例服务在 K8s 上快速部署\n    https://github.com/OpenAtomFoundation/pika/pull/1243\n+ 实现了在 MiniKube 环境中部署 Pika\n    https://github.com/OpenAtomFoundation/pika/pull/1330\n+ 给 pika-operator 添加 E2E 测试\n    https://github.com/OpenAtomFoundation/pika/pull/1347\n\n## 8 跨平台编译\n\n在 v3.5.0 版本中，Pika 呈现出一种全面性的蓬勃发展态势，得以在不同操作系统平台上展现其优越性。此版本的突破性之处在于，Pika 实现了对 MacOS、CentOS 和 Ubuntu 这些主要平台的完整编译和使用支持。这个举措不仅仅体现了我们对多样化技术环境的关注，也是为了最大程度地拓展用户基础，为广泛的用户群体提供灵活、高效的数据库解决方案。这种跨平台兼容性的加强将 Pika 推向更广阔的技术生态。\n\n+ 支持 MacOS 平台\n    https://github.com/OpenAtomFoundation/pika/pull/1372\n\n## 9 多平台集成测试及单元测试\n\n在 v3.5.0 版本中，我们迈出了一个令人瞩目的步伐，不仅在多个主要操作系统平台上实现了支持，还在测试领域实施了全面升级。我们为 Ubuntu、CentOS 和 MacOS 这三大平台搭建了持续集成（CI）环境，以确保系统的完整性和稳定性。在测试方面，我们引入了更为广泛的覆盖，包括 Go 语言的集成测试、TCL 的单元测试以及 Python 的端到端（E2E）测试。通过这些测试策略的升级，我们在确保系统性能和可靠性方面迈出了更大的一步。\n\n+ 新增 CentOS 环境下的 CI\n    https://github.com/OpenAtomFoundation/pika/pull/1534\n+ 新增 MacOS 环境下的 CI\n    https://github.com/OpenAtomFoundation/pika/pull/1769\n+ 新增 E2E 测试框架\n    https://github.com/OpenAtomFoundation/pika/pull/1347\n+ 新增在 Github CI Workflow 中添加 CMake 编译环境\n    https://github.com/OpenAtomFoundation/pika/pull/1268\n+ 新增在 TCL 脚本中 populate 方法模拟 Redis debug populate 方法，用以填充测试数据\n    https://github.com/OpenAtomFoundation/pika/pull/1693\n+ 新增在 blackwidow 中添加 CMake 文件，添加对 blackwidow 的单元测试\n    https://github.com/OpenAtomFoundation/pika/pull/1246\n+ 移植 Redis 测试脚本\n    https://github.com/OpenAtomFoundation/pika/pull/1357\n\n## 10 Others\n\n若您有任何疑问，诚挚欢迎您扫描微信二维码，加入我们的交流群，与一众志同道合的成员展开深入的讨论，我们热切期待与您分享见解、交流心得，为共同的技术探索和创新之旅添砖加瓦。在这个群体中，我们将以卓越的智慧和互动的合作精神，构建出一个相互学习、不断进步的技术共同体。\n\n![2023-08-25-Pika-3.5.0](2023-08-25-Pika-3.5.0-connect.png)"},{"id":"pika-blackwidow","metadata":{"permalink":"/blog/pika-blackwidow","source":"@site/blog/2020-7-16-pika-blackwidow.md","title":"Pika Blackwidow 引擎数据存储格式","description":"Blackwidow本质上是基于rocksdb的封装，使本身只支持kv存储的rocksdb能够支持多种数据结构, 目前Blackwidow支持五种数据结构的存储：String结构(实际上就是存储key, value), Hash结构，List结构，Set结构和ZSet结构， 因为Rocksdb的存储方式只有kv一种， 所以上述五种数据结构最终都要落盘到Rocksdb的kv存储方式上，下面我们展示Blackwidow和rocksdb的关系并且说明我们是如何用kv来模拟多数据结构的。","date":"2020-07-16T00:00:00.000Z","tags":[],"readingTime":12.29,"hasTruncateMarker":false,"authors":[{"name":"Axlgrep","title":"Pika 开源社区"}],"frontMatter":{"title":"Pika Blackwidow 引擎数据存储格式","slug":"pika-blackwidow","authors":[{"name":"Axlgrep","title":"Pika 开源社区"}],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"What's new in Pika v3.5.0","permalink":"/blog/Pika-3.5.0"},"nextItem":{"title":"pika_port 迁移工具","permalink":"/blog/Pika-Tools-Port-Bin"}},"content":"Blackwidow本质上是基于rocksdb的封装，使本身只支持kv存储的rocksdb能够支持多种数据结构, 目前Blackwidow支持五种数据结构的存储：String结构(实际上就是存储key, value), Hash结构，List结构，Set结构和ZSet结构， 因为Rocksdb的存储方式只有kv一种， 所以上述五种数据结构最终都要落盘到Rocksdb的kv存储方式上，下面我们展示Blackwidow和rocksdb的关系并且说明我们是如何用kv来模拟多数据结构的。\n\n![pika-blackwidow-1](pika-blackwidow-1.png)\n\n## 1. String结构的存储\nString本质上就是Key, Value, 我们知道Rocksdb本身就是支持kv存储的， 我们为了实现Redis中的expire功能，所以在value后面添加了4 Bytes用于存储timestamp, 作为最后Rocksdb落盘的kv格式，下面是具体的实现方式:\n\n![pika-blackwidow-2](pika-blackwidow-2.png)\n\n如果我们没有对该String对象设置超时时间，则timestamp存储的值就是默认值0， 否则就是该对象过期时间的时间戳， 每次我们获取一个String对象的时候， 首先会解析Value部分的后四字节， 获取到timestamp做出判断之后再返回结果。\n\n## 2. Hash结构的存储\nblackwidow中的hash表由两部分构成，元数据(meta_key, meta_value), 和普通数据(data_key, data_value), 元数据中存储的主要是hash表的一些信息， 比如说当前hash表的域的数量以及当前hash表的版本号和过期时间(用做秒删功能), 而普通数据主要就是指的同一个hash表中一一对应的field和value，作为具体最后Rocksdb落盘的kv格式，下面是具体的实现方式:\n1. 每个hash表的meta_key和meta_value的落盘方式:\n![pika-blackwidow-3](pika-blackwidow-3.png)\n\nmeta_key实际上就是hash表的key, 而meta_value由三个部分构成: 4Bytes的Hash size(用于存储当前hash表的大小) + 4Bytes的Version(用于秒删功能) + 4Bytes的Timestamp(用于记录我们给这个Hash表设置的超时时间的时间戳， 默认为0)\n\n2. hash表中data_key和data_value的落盘方式:\n![pika-blackwidow-4](pika-blackwidow-4.png)\n\ndata_key由四个部分构成: 4Bytes的Key size(用于记录后面追加的key的长度，便与解析) + key的内容 + 4Bytes的Version + Field的内容， 而data_value就是hash表某个field对应的value。\n\n3. 如果我们需要查找一个hash表中的某一个field对应的value, 我们首先会获取到meta_value解析出其中的timestamp判断这个hash表是否过期， 如果没有过期， 我们可以拿到其中的version, 然后我们使用key, version，和field拼出data_key, 进而找到对应的data_value（如果存在的话)\n\n## 3. List结构的存储\nblackwidow中的list由两部分构成，元数据(meta_key, meta_value), 和普通数据(data_key, data_value), 元数据中存储的主要是list链表的一些信息， 比如说当前list链表结点的的数量以及当前list链表的版本号和过期时间(用做秒删功能), 还有当前list链表的左右边界(由于nemo实现的链表结构被吐槽lrange效率低下，所以这次blackwidow我们底层用数组来模拟链表，这样lrange速度会大大提升，因为结点存储都是有序的), 普通数据实际上就是指的list中每一个结点中的数据，作为具体最后Rocksdb落盘的kv格式，下面是具体的实现方式\n1. 每个list链表的meta_key和meta_value的落盘方式:\n![pika-blackwidow-5](pika-blackwidow-5.png)\n\nmeta_key实际上就是list链表的key, 而meta_value由五个部分构成: 8Bytes的List size(用于存储当前链表中总共有多少个结点) + 4Bytes的Version(用于秒删功能) + 4Bytes的Timestamp(用于记录我们给这个List链表设置的超时时间的时间戳， 默认为0) + 8Bytes的Left Index（数组的左边界) + 8Bytes的Right Index(数组的右边界)\n\n2. list链表中data_key和data_value的落盘方式:\n![pika-blackwidow-6](pika-blackwidow-6.png)\n\ndata_key由四个部分构成: 4Bytes的Key size(用于记录后面追加的key的长度，便与解析) + key的内容 + 4Bytes的Version + 8Bytes的Index(这个记录的就是当前结点的在这个list链表中的索引)， 而data_value就是list链表该node中存储的值\n\n## 4. Set结构的存储\nblackwidow中的set由两部分构成，元数据(meta_key, meta_value), 和普通数据(data_key, data_value), 元数据中存储的主要是set集合的一些信息， 比如说当前set集合member的数量以及当前set集合的版本号和过期时间(用做秒删功能), 普通数据实际上就是指的set集合中的member，作为具体最后Rocksdb落盘的kv格式，下面是具体的实现方式：\n1. 每个set集合的meta_key和meta_value的落盘方式:\n![pika-blackwidow-7](pika-blackwidow-7.png)\n\nmeta_key实际上就是set集合的key, 而meta_value由三个部分构成: 4Bytes的Set size(用于存储当前Set集合的大小) + 4Bytes的Version(用于秒删功能) + 4Bytes的Timestamp(用于记录我们给这个set集合设置的超时时间的时间戳， 默认为0)\n\n2. set集合中data_key和data_value的落盘方式:\n![pika-blackwidow-8](pika-blackwidow-8.png)\n\ndata_key由四个部分构成: 4Bytes的Key size(用于记录后面追加的key的长度，便与解析) + key的内容 + 4Bytes的Version + member的内容， 由于set集合只需要存储member, 所以data_value实际上就是空串\n\n## 5. ZSet结构的存储\nblackwidow中的zset由两部部分构成，元数据(meta_key, meta_value), 和普通数据(data_key, data_value), 元数据中存储的主要是zset集合的一些信息， 比如说当前zset集合member的数量以及当前zset集合的版本号和过期时间(用做秒删功能), 而普通数据就是指的zset中每个member以及对应的score, 由于zset这种数据结构比较特殊，需要按照memer进行排序，也需要按照score进行排序， 所以我们对于每一个zset我们会按照不同的格式存储两份普通数据, 在这里我们称为member to score和score to member，作为具体最后Rocksdb落盘的kv格式，下面是具体的实现方式：\n1. 每个zset集合的meta_key和meta_value的落盘方式:\n![](https://i.imgur.com/RhZ8KMw.png)\n\nmeta_key实际上就是zset集合的key, 而meta_value由三个部分构成: 4Bytes的ZSet size(用于存储当前zSet集合的大小) + 4Bytes的Version(用于秒删功能) + 4Bytes的Timestamp(用于记录我们给这个Zset集合设置的超时时间的时间戳， 默认为0)\n\n2. 每个zset集合的data_key和data_value的落盘方式(member to score):\n![](https://i.imgur.com/C85Ba5Z.png)\n\nmember to socre的data_key由四个部分构成：4Bytes的Key size(用于记录后面追加的key的长度，便与解析) + key的内容 + 4Bytes的Version + member的内容， data_value中存储的其member对应的score的值，大小为8个字节，由于rocksdb默认是按照字典序进行排列的，所以同一个zset中不同的member就是按照member的字典序来排列的(同一个zset的key size, key, 以及version，也就是前缀都是一致的，不同的只有末端的member).\n\n3. 每个zset集合的data_key和data_value的落盘方式(score to member):\n![](https://i.imgur.com/QV9XHEk.png)\n\nscore to member的data_key由五个部分构成：4Bytes的Key size(用于记录后面追加的key的长度，便与解析) + key的内容 + 4Bytes的Version + 8Bytes的Score + member的内容， 由于score和member都已经放在data_key中进行存储了所以data_value就是一个空串，无需存储其他内容了，对于score to member中的data_key我们自己实现了rocksdb的comparator，同一个zset中score to member的data_key会首先按照score来排序， 在score相同的情况下再按照member来排序\n\n\n## Blackwidow相对于Nemo有哪些优势\n\n1. Blackwidow采用了rocksdb的column families的新特性，将元数据和实际数据分开存放(对应于上面的meta数据和data数据), 这种存储方式相对于Nemo将meta, data混在一起存放更加合理， 并且可以提升查找效率(比如info keyspace的效率会大大提升)\n2. Blackwidow中参数传递大量采用Slice而Nemo中采用的是std::string, 所以Nemo会有很多没有必要的string对象的构造函数以及析构函数的调用，造成额外的资源消耗，而Blackwidow则不会有这个问题\n3. Blackwidow对kv模拟多数据结构的存储格式上做了重新设计(具体可以参考Nemo引擎数据存储格式和本篇文章)，使之前在Nemo上出现的一些无法解决的性能问题得以解决，所以Blackwidow的多数据结构在某些场景下性能远远优于Nemo\n4. 原来Nemo对多数据结构的Key的长度最大只能支持到256 Bytes，而Blackwidow经过重新设计，放开了多数据结构Key长度的这个限制\n5. Blackwidow相对于Nemo更加节省空间，Nemo由于需要nemo-rocksdb的支持，所以不管在meta还是data数据部分都追加了version和timestamp这些信息，并且为了区分meta_key和data_key, 在最前面加入s和S(拿Set数据结构打比方)，Blackwidow在这方面做了优化，使同样的数据量下Blackwidow所占用的空间比Nemo要小(举个例子，Blackwidow中List结构中的一个Node就比Nemo中的一个Node节省了16 Bytes的空间)\n6. Blackwidow在锁的实现上参照了RocksDB事务里锁的实现方法，而弃用了之前Nemo的行锁，所以在多线程对同一把锁有抢占的情况下性能会有所提升"},{"id":"Pika-Tools-Port-Bin","metadata":{"permalink":"/blog/Pika-Tools-Port-Bin","source":"@site/blog/2020-04-26-Pika-Tools-Port-Bin.md","title":"pika_port 迁移工具","description":"项目作者：","date":"2020-04-26T00:00:00.000Z","tags":[],"readingTime":2.56,"hasTruncateMarker":false,"authors":[{"name":"于雨","title":"Pika 开源社区"}],"frontMatter":{"title":"pika_port 迁移工具","slug":"Pika-Tools-Port-Bin","authors":[{"name":"于雨","title":"Pika 开源社区"}],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"Pika Blackwidow 引擎数据存储格式","permalink":"/blog/pika-blackwidow"}},"content":"## 项目作者：\n[AlexStocks](https://github.com/alexstocks)\n\n## 适用版本：\n3.1 和 2.x\n\n## 项目地址：\n[https://github.com/ipixiu/pika-tools](https://github.com/ipixiu/pika-tools)\n\n[https://github.com/Axlgrep/pika-tools 长期维护地址需自行编译](https://github.com/Axlgrep/pika-tools)\n\n## 二进制包：\n[https://github.com/ipixiu/pika-port-bin](https://github.com/ipixiu/pika-port-bin)\n\n## 功能：\n将Pika中的数据在线迁移到Pika、Redis（支持全量、增量同步）\n\n## 开发背景：\n之前Pika项目官方提供的pika_to_redis工具仅支持离线将Pika的DB中的数据迁移到Pika、Redis, 且无法增量同步，该工具可以直接伪装为一个Pika的从库，将主库数据通过同步获取并转发给Pika、Redis，同时并支持增量同步\n\n\n## 实现：\n### trysync线程\n1. 尝试与主库建立同步关系  \n2. 如果需要全同步，则在接收到master的db之后，启动migrator和sender线程将db里面的数据发送给Pika、Redis  \n3. 启动Slaveping线程定期给主库发送心跳，完成建立主从关系\n\n### binlog_receiver线程\n1. 接收主库发送过来的binlog并且将其解析成redis命令\n2. 将redis命令转发给Pika、Redis\n\n### migrator线程\n1. 扫描不同数据类型的分库\n2. 将key进行解析成响应数据Pika、redis指令\n3. 将解析好的redis指令加载到sender的发送buf中\n\n### sender线程\n1. 从发送buf中读取数据，以非阻塞方式向Pika、redis发送数据\n2. 接收Pika、redis返回的结果并解析，如果出现错误则显示错误结果\n\n## 使用帮助：\n```\nUsage: \n       pika_port [-h] [-t local_ip -p local_port -i master_ip -o master_port\n                  -m forward_ip -n forward_port -x forward_thread_num -y forward_passwd]\n                  -f filenum -s offset -w password -r rsync_dump_path  -l log_path\n        -h     -- show this help\n        -t     -- local host ip(OPTIONAL default: 127.0.0.1)\n        -p     -- local port(OPTIONAL)\n        -i     -- master ip(OPTIONAL default: 127.0.0.1)\n        -o     -- master port(REQUIRED)\n        -m     -- forward ip(OPTIONAL default: 127.0.0.1)\n        -n     -- forward port(REQUIRED)\n        -x     -- forward thread num(OPTIONAL default: 1)\n        -y     -- forward password(OPTIONAL)\n        -f     -- binlog filenum(OPTIONAL default: local offset)\n        -s     -- binlog offset(OPTIONAL default: local offset)\n        -w     -- password for master(OPTIONAL)\n        -r     -- rsync dump data path(OPTIONAL default: ./rsync_dump)\n        -l     -- local log path(OPTIONAL default: ./log)\n        -b     -- max batch number when port rsync dump data (OPTIONAL default: 512)\n        -d     -- daemonize(OPTIONAL)\n  example: ./pika_port -t 127.0.0.1 -p 12345 -i 127.0.0.1 -o 9221 -m 127.0.0.1 -n 6379 -x 7 -f 0 -s 0 -w abc -l ./log -r ./rsync_dump -b 512 -d\n```"}]}}